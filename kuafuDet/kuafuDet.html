
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

	<title>Welcome to KuafuDet's Homepage</title>

	<link type="text/css" rel="stylesheet" href="./img/main.css">

</head>

<body>

	<div class="outer"></div>
	<div class="main">
		<table border="0" width="100%" cellpadding="0">
			<tbody><tr> 
			<td width="25%" align="right">
			<img src="./img/icon.png"><strong><i>KuafuDet</i></strong>&nbsp;&nbsp;&nbsp;&nbsp;</td>
			<td width="75%">
			<div class="title">Automated poisoning attacks and defenses in malware detection systems: An adversarial
machine learning approach</div>
			

			<!--<p align="left"><a href="http://www.sqslab.com/senchen" target="_blank">Sen Chen</a><sup>1,2</sup>
			&nbsp;&nbsp;
			<a href="http://www.cs.ecnu.edu.cn/xueminhui/" target="_blank">Minhui Xue</a><sup>1,3</sup>
			&nbsp;&nbsp;
			<a href="http://www.sqslab.com/" target="_blank">Lingling Fan</a><sup>1,2</sup>
			&nbsp;&nbsp;
			<a href="http://www.cs.ucsb.edu/~shuanghao/" target="_blank">Shuang Hao</a><sup>5</sup>
			&nbsp;&nbsp;
			<a href="http://www.sqslab.com/" target="_blank">Lihua Xu</a><sup>1</sup>
			&nbsp;&nbsp;
			<a href="http://nsec.sjtu.edu.cn/~hjzhu/" target="_blank">Haojin Zhu</a><sup>4</sup>
			</br>
			<br><sup>1</sup>East China Normal University, Shanghai, China
			<br><sup>2</sup>Nanyang Technological University, Singapore
			<br><sup>3</sup>New York University Shanghai, Shanghai, China
			<br><sup>4</sup>Shanghai Jiao Tong University, Shanghai, China
			<br><sup>5</sup>University of California, Santa Barbara, USA
			</br>
		-->
		<!-- &nbsp;&nbsp;&nbsp;&nbsp; 
		<p>Contact: ecnuchensen@gmail.com &nbsp;&nbsp; minhuixue@nyu.edu</p>   
		</td>-->
</tbody></table>
		<hr>
		<p>
			</p><div class="subtitle">Overview</div>
		<p></p>
		<p>
			Today, sophisticated attackers can adapt by maximally sabotaging machine-learning classifiers via polluting training data, rendering most recent machine learning-based malware detection tools (such as <i>Drebin</i>, <i>DroidAPIMiner</i>, and <i>MaMaDroid</i>) ineffective. 

		<p>
			We explore the feasibility of constructing crafted malware samples; examine how machine-learning classifiers can be misled under three different threat models; then conclude that injecting carefully crafted data into training data can significantly reduce detection accuracy. 

		<p>
			We propose <i>KuafuDet</i>, a two-phase learning enhancing approach that learns mobile malware by adversarial detection. KuafuDet includes an offline training phase that selects and extracts features from the training set, and an online detection phase that utilizes the classifier trained by the first phase. 
		</p>
		<p>	
			To further address the adversarial environment, these two phases are intertwined through a self-adaptive learning scheme, wherein an automated camouflage detector is introduced to filter the suspicious false negatives and feed them back into the training phase. We finally show KuafuDet significantly reduces false negatives and boosts the detection accuracy by at least 15%.
		</p>
		<p>
			<strong>Contact: ecnuchensen AT gmail.com</strong>
		</p>
		<hr>
		<p>
			</p><div class="subtitle">Publication </div>
		<p></p>
		<p>
			Automated poisoning attacks and defenses in malware detection systems: An adversarial machine learning approach
		</br>
			<br>Sen Chen, Minhui Xue, Lingling Fan, Shuang Hao, Lihua Xu, Haojin Zhu, Bo Li Elsevier Computers & Security
		</p>
		<hr>
		<p>
			</p><div class="subtitle">Policy</div>
		<p></p>
		<p>
			We make the malicious Android applications used in the paper as well as our experiments results publicly availale to other researchers. 
		</p>
		<p>
                <!--To avoid these results from being misused, we feel the need to have some sorts of authentication
                in place to verify user identity or require necessary justification, instead
                of making the results completely public.--> 
                If you are interested in getting access to our experiments results, please read the following instructions
                carefully.
                </p>
                <p>
                (1) If you are currently in academia: <br>
                </p>
                <p>
                    <table>
                    <tbody><tr><td> <p>

                   (a) If you are a student, please ask your advisor
                       to send us an email for the access.  If you are a faculty, please send
                       us the email from your university's email account.</p>
                <p>
                   (b) In your email, please include your name, affiliation, and homepage.  
                </p>
                    </td></tr></tbody></table> </p>
                 <p>
                (2) If you are currently in industry:
                </p>
                <p>
                 <table>
                    <tbody><tr><td> <p>
                   (a) Please send us an email from your company's email account. In the email,
                       please briefly introduce yourself (e.g., name) and your company.</p>
                   <!--<p>
                   (b) In the email, please attach a justification letter (<i>PDF</i> format) in
                       official letterhead. The justification letter needs to acknowledge the
                       "<strong><i>KuafuDet</i></strong>" project and state clearly the reasons why the
                       results are being requested. </p>
                       </td></tr></tbody></table>
                </p>-->
                <p>
                <Strong>Please send your request emails to Sen Chen (ecnuchensen AT gmail.com)</strong>
		</p></tabody></table>
		<hr>
		<div class="subtitle">Dataset </div>
                <p>
                  Our dataset (252,900 APKs) consists of 242,500 benign applications that are downloaded from Google Play Store, and the other 10,400 malicious APK files where 1,260 have been validated in Genome project and the remaining are downloaded from Drebin (4,300 APKs), Pwnzen Infotech Inc and Contagio (340 APKs). <!--<a class="download" href="https://drive.google.com/open?id=0B02lgwIRHYY9bDlxa254a0YtQXM" target="_blank">download</a>-->
                </p>
                <!--<P>
                  The collection of dataset used was strictly following the Privacy Policy of the Pwnzen Infotech Inc., and conformed to the non-disclosure agreement (NDA) of the Pwnzen Infotech Inc. What we can release, however, are the malicious dataset of Contagio, which we used as subset of our experiments.
                </P>-->
                <div class="subtitle">Features </div>
                <p>
                  The features considered in this study are classified into two categories: syntax features (175) and semantic features (20). <!--<a class="download" href="https://drive.google.com/open?id=0B02lgwIRHYY9Vm5kMkJCZlV2RE0" target="_blank">download</a>-->
                </p>
                <div class="subtitle">Training files (camouflaged)</div>
                <p>
                  We propose that poisoning attack can be exhibited by three types of attackers (i.e., weak, strong, sophisticated attacker) in the real world. We show that our poisoning attack is able to mislead machine learning classifiers (e.g., SVM, RF, KNN). <!--<a class="download" href="https://drive.google.com/open?id=0B02lgwIRHYY9STRMemY5cHpIdUE" target="_blank">download</a>-->
                </p>
    			<hr>
		<!--<p>
			</p><div class="subtitle">Acknowledgements</div>
		<p></p>
		<p>
			We would like to thank Pwnzen Infotech Inc. for providing us with a copy of mobile malware to conduct the study, especially the Pwnzen Infotech Inc. co-founder Zhushou Tang for exchanging helpful industry experience. 
		</p>
		<p>
		</p>		
		<hr>-->
	</div>
 	<div class="outer"></div>
<div id="cntvlive2-is-installed"></div></body></html>
